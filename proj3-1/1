<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Pathtracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2022</h1>
<h1 align="middle">Project 3: Pathtracer</h1>
<h2 align="middle">Justin Radatti and Dakshina Palasamudrum, CS184-0xda-ju</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>
</p>

<h3 align="middle">Part 1: Ray Generation and Scene Intersection</h3>

<p>
</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/CBspheres.png" align="middle" width="400px"/>
        <figcaption align="middle">Spheres</figcaption>
      </td>
      <td>
        <img src="images/CBgems.png" align="middle" width="400px"/>
        <figcaption align="middle">Gems</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>

<h3 align="middle">Part 2: Bounding Volume Hierarchy </h3>

<p>Our BVH algorithm recursively splits the scene primitives into BVHNodes. The construct_bvh() function takes in two iterators, start and end, as parameters and first finds the bounding box that encapsulates all the primitives in the range(inclusively) and makes a new BVHNode called ‘node’. If the number of primitives is small enough, we set the start and end fields of ‘node’ and return it as the base case. If the bounding box wasn’t small enough, we need to partition the primitives into a left and a right group. To do so, we find the longest axis of the bounding box using the BBox.extent field and then find the average of centroids along that axis. Next, we partition the primitives into two groups based on their centroid location along the longest axis relative to the average centroid location. In order to avoid infinite recursion, we then check if there is at least one primitive in each group and if there isn’t we adjust the iterators accordingly. Finally, we recurse one the construct_bvh() function and set the result to node->left and node->right. 
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption align="middle">Lucy(133796 primitives, 0.6120 seconds)</figcaption>
      </td>
      <td>
        <img src="images/maxplanck.png" align="middle" width="400px"/>
        <figcaption align="middle">MaxPlanck(50801 primitives, 0.0575 seconds)</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>

<p> I used cow.dae and beetle.dae to compare the rendering times between using and not using the Bounded Volume Hierarchy optimization. Cow.dae and beetle.dae consist of 5856 and 7558 primitives, respectively. Without using BVH, the beetle took 9.47 seconds and the cow took 6.69 seconds on my local machine. The cow and beetle averaged 1506 and 1947 intersection tests per ray, respectively. Alternatively, using BVH, cow.dae took 0.037 seconds and the beetle took 0.034 seconds. The BVH optimization decreases the intersection tests per ray to an average of 4 and 3 for cow and beetle, respectively. 
</p>

<h3 align="middle">Part 3: Direct Illumination </h3>
 
<p>The estimate_direct_lighting_hemisphere() function takes in a ray ‘r’ and an intersection ‘isect’ with the goal of finding the reflectance at the hotpoint ’hit_p’. To do so, we use Monte Carlo estimation to average the reflectances of ‘num_samples’ sample and scale by the probability of each sample, (1/(2*PI)). For each sample, we cast a different ray ‘ray’ from ‘hit_p’ and check if it intersects with a scene primitive, storing the intersection in ‘new_isect’. If ‘ray’ collides with something, we measure the radiance, ‘radiance’,  with zero_bounce_radiance() using ’new_isect’ and measure the ratio ‘f’ by calling ‘insect.bsdf->f()’. Then, we measure the reflectance at ‘hit_p’ by doing “(radiance * f * cos_theta(w_in)) / pdf” where cos_theta(w_in) is the angle between ‘ray’ and the surface normal.  
</p>

<p>The estimate_direct_lighting_importance() function Follows a similar process as estimate_direct_lighting_hemisphere() except the sample directions are not taken uniformly around a hemisphere. Instead, the samples are taken in the direction of the lights in the scene. If the sample intersects an object in the scene, the object is between the light and 'hit_p' which implies there is a shadow at 'hit_p'. Thus, we only add to 'L_out' when the ray from 'hit_p' in the sampled direction does not hit an object before the light. More specifically, the algorithm is as follows. For every light in the scene, we take ’ns_area_light’ samples using SceneLight::sample_L(), which samples the light between the light source and the point ‘hit_p’. Next, we add the sampled light to the total light ‘L_out’ and scale by the pdf returned by sample_L(). Finally, we divide 
‘L_out’ by ’ns_area_light’ to complete our Monte Carlo estimation.
</p>

<p> 
Examples of Hemisphere light sampling below:
</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/CBbunny_H_16_8.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling. 64 samples. </figcaption>
      </td>
      <td>
        <img src="images/hemisphere3.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling. 64 samples. </figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/hemisphere1.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling. 64 samples. </figcaption>
      </td>
      <td>
        <img src="images/hemisphere2.png" align="middle" width="400px"/>
        <figcaption align="middle">Hemisphere sampling. 64 samples. </figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>

<p> 
Examples of Importance light sampling below:
</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/bunny_1_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 1 samples. </figcaption>
      </td>
      <td>
        <img src="images/importance3.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 64 samples. </figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/importance1.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 64 samples. </figcaption>
      </td>
      <td>
        <img src="images/importance2.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 64 samples. </figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>

<p> 
Using Importance Sampling to render with 1, 4, 16, and 64 light rays and with 1 sample per pixel shown below. The noise in the soft shadows decreases as we increase the number of rays.
</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/dragon_1_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 1 light rays with 1 sample per pixel. </figcaption>
      </td>
      <td>
        <img src="images/dragon_1_4.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 4 light rays with 1 sample per pixel. </figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/dragon_1_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 16 light rays with 1 sample per pixel. </figcaption>
      </td>
      <td>
        <img src="images/dragon_1_64.png" align="middle" width="400px"/>
        <figcaption align="middle">Light sampling. 64 light rays with 1 sample per pixel. </figcaption>
      </td>
    </tr>
  </table>
</div>

<p> 
The main difference between estimate_direct_lighting_hemisphere() and estimate_direct_lighting_importance() is that importance lighting has less noise. This is due to the sampling method. Since hemisphere estimation samples uniformly around a hemisphere, there is more margin of error to miss the light sources compared to importance lighting. In importance lighting, we only sample in the direction of the light. Thus, the accuracy is higher and there is less false negatives. The images above clearly show the advantage of importance sampling; with 1 sample and 1 ray hemisphere sampling is unrecognizable while importance sampling is relatively clear. All in all, the images rendered with hemisphere sampling are more grainy than the images rendered with Importance sampling.
</p>

<h3 align="middle">Part 4: Global Illumination </h3>

<p>Our ‘at_least_one_bounce_radiance()’ function implements indirect lighting by recursively summing the lighting of ‘max_ray_depth’ bounces through the scene(or sometimes less due to Russian Roulette). Our base case is if ‘r.depth <= 1’, we return the zero vector. Otherwise, we add the radiance using ‘one_bounce_radiance()’ with the given ‘ray’ and ‘isect’ to L_out. Next, we use the ‘BSDF::sample_f()’ function to get the ratio of the bsdf at ‘hit_p’, as well as the pdf and sampled direction ‘wi’. We then shoot a ray, ‘ray’, into the scene in direction ‘wi’ and set its depth to ‘r.depth - 1’. If the ray intersects with something, we follow the ray and calculate the radiance at the next hit point. More concretely, if the ray, ‘ray’, intersects a scene primitive at ‘new_isect’, we increment L_out by “at_least_one_bounce_radiance(ray, new_isect) * sample * cos_theta(wi) / pdf / cpdf” where sample is the return value of ‘sample_f()’ and cpdf is set to 0.7. However there is one more wrinkle, we only add the previous value to L_out with probability 0.3. To implement this we used the ‘coin_flip()’’ function and an if statement. 
</p>

<p>Pictured below are two scenes rendered with Global Illumination:</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/spheres1024.png" align="middle" width="400px"/>
        <figcaption align="middle">Spheres rendered with 1024 samples per pixel(globel illumination)</figcaption>
      </td>
      <td>
        <img src="images/bunny1024.png" align="middle" width="400px"/>
        <figcaption align="middle">Bunny rendered with 1024 samples per pixel(global illumination)</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>

<p>Below is CBspheres_lambertian.dae rendered with <b>only</b> direct illumination(left) and <b>only</b> indirect illumination(right)</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/spheresOnlyDirect.png" align="middle" width="400px"/>
        <figcaption align="middle">Spheres rendered with 1024 samples per pixel(only direct illumination)</figcaption>
      </td>
      <td>
        <img src="images/spheresOnlyIndirect.png" align="middle" width="400px"/>
        <figcaption align="middle">Spheres rendered with 1024 samples per pixel(only indirect illumination)</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>




<h3 align="middle">Part 5: Adaptive Sampling </h3>

